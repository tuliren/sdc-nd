{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "- Gradient descent\n",
    "  - Descend a mountain\n",
    "  - Descend in the direction that will decrease the error the most\n",
    "  - Until a minimum error is found\n",
    "- Least squares\n",
    "  - error = (prediction - actual)^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear to logistic regression\n",
    "\n",
    "- Linear regression\n",
    "  - Predict values on a continuous spectrum\n",
    "\n",
    "- Logistic regression\n",
    "  - Classify data among discrete classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "- Chain logistic regression layers together\n",
    "  - Input layer\n",
    "  - Hidden layer\n",
    "  - Output layer\n",
    "  \n",
    "  <img src=\"images/perceptron.jpg\" width=\"50%\" height=\"50%\" />\n",
    "  \n",
    "- Perceptron\n",
    "  - Articial neuron\n",
    "  - Each one looks at input data and decides how to categorize that data.\n",
    "  - Output is always 0 or 1.\n",
    "- Weights\n",
    "  - Input is multipled by a weight value\n",
    "  - Start as random values\n",
    "  - Neural network is trained by adjusting weights\n",
    "  - Higher weight means that this input is more important than other inputs\n",
    "  - Weighted input values are summed to a single value\n",
    "  - Matrix of weights: $W$\n",
    "  - Individual weight: $w$\n",
    "- Activation function\n",
    "  - Result of perceptron's summation is turned into output signal by activation function\n",
    "\n",
    "  - Heaviside step function\n",
    "    - `f(h) = h >= 0 ? 1 : 0`\n",
    "    <img src=\"images/heaviside-step-function.png\" width=\"30%\" height=\"30%\" />\n",
    "\n",
    "- Bias: $b$, moves values in one direction or another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def test(weight1, weight2, bias, test_inputs, correct_outputs):    \n",
    "    outputs = []\n",
    "\n",
    "    # Generate and check output\n",
    "    for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "        linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "        output = int(linear_combination >= 0)\n",
    "        is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "        outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "    # Print output\n",
    "    num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "    output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "    if not num_wrong:\n",
    "        print('Nice!  You got it all correct.\\n')\n",
    "    else:\n",
    "        print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "\n",
    "    print(output_frame.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AND perceptron\n",
    "<img src=\"images/and-perceptron.png\" width=\"30%\" height=\"30%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      "Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "      0          0                   -10                    0          Yes\n",
      "      0          1                    -5                    0          Yes\n",
      "      1          0                    -5                    0          Yes\n",
      "      1          1                     0                    1          Yes\n"
     ]
    }
   ],
   "source": [
    "weight1 = 5\n",
    "weight2 = 5\n",
    "bias = -10\n",
    "\n",
    "# DON'T CHANGE ANYTHING BELOW\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [False, False, False, True]\n",
    "\n",
    "test(weight1, weight2, bias, test_inputs, correct_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OR perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      "Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "      0          0                    -5                    0          Yes\n",
      "      0          1                     0                    1          Yes\n",
      "      1          0                     0                    1          Yes\n",
      "      1          1                     5                    1          Yes\n"
     ]
    }
   ],
   "source": [
    "weight1 = 5\n",
    "weight2 = 5\n",
    "bias = -5\n",
    "\n",
    "# DON'T CHANGE ANYTHING BELOW\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [False, True, True, True]\n",
    "\n",
    "test(weight1, weight2, bias, test_inputs, correct_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOT perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      "Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "      0          0                     0                    1          Yes\n",
      "      0          1                    -1                    0          Yes\n",
      "      1          0                     0                    1          Yes\n",
      "      1          1                    -1                    0          Yes\n"
     ]
    }
   ],
   "source": [
    "weight1 = 0\n",
    "weight2 = -1\n",
    "bias = 0\n",
    "\n",
    "# DON'T CHANGE ANYTHING BELOW\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [True, False, True, False]\n",
    "outputs = []\n",
    "\n",
    "test(weight1, weight2, bias, test_inputs, correct_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR perceptron\n",
    "<img src=\"images/xor-perceptron.png\" width=\"50%\" height=\"50%\" />\n",
    "\n",
    "- A: `NOT`\n",
    "- B: `AND`\n",
    "- C: `OR`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network\n",
    "<img src=\"images/simple-network.png\" width=\"30%\" height=\"30%\" />\n",
    "\n",
    "- Use activation functions that are continuous and differentiable, possible to train using gradient descent\n",
    "\n",
    "- Logistic (sigmoid) activation function\n",
    "  - $sigmoid(x) = 1 / (1 + e^{-x})$\n",
    "  - Output $(0, 1)$\n",
    "  - Can be interpreted as a probability for success.\n",
    "  - Same formulation as logistic regression.\n",
    "  - Turn perceptron into neural network.\n",
    "  <img src=\"images/sigmoid.png\" width=\"30%\" height=\"30%\" />\n",
    "\n",
    "- Circles: units\n",
    "- Boxes: operations\n",
    "\n",
    "- $h = \\sum w_i x_i + b$\n",
    "- $y = f(h)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "0.432907095035\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    # TODO: Implement sigmoid function\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "inputs = np.array([0.7, -0.3])\n",
    "weights = np.array([0.1, 0.8])\n",
    "bias = -0.1\n",
    "\n",
    "# TODO: Calculate the output\n",
    "output = sigmoid(np.dot(weights, inputs) + bias)\n",
    "\n",
    "print('Output:')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
